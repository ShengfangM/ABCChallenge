# -*- coding: utf-8 -*-
"""ABCdataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WHb-gAAdkpRQ59LCab2atf1M6t3m1I1i

# Get the dataset from h5 file

Bands informaton of sentinel-2 image: aerosol,blue,green,red,rd1, rd2,rd3,nir,nirn,wv,swir1-3
"""

import h5py
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

"""
Create vegetation indices(VI) and water indices(WI)
Image shape is [N,C,H,W] 
N - number of images, C - channels, 
H - height, W - width 

Attributes:
    data : sentinel data
"""
def ndvi2_sentinel(data):
  """
  create NDVI from sentinel-2 image

  NDVI = NIR - Red / NIR + RED
  NIR_842nm = Band 8
  Red = Band 4

  return NDVI as numpy array
  """
  nir2 = data[:,6]
  red = data[:,3]
  ndvi = (nir2 - red) / (nir2 + red)
  ndvi[np.isnan(ndvi)] = -1
  return ndvi

def ndvi_sentinel(data):
  """ 
  create NDVI from sentinel-2 image

  NDVI = NIR - Red / NIR + RED
  NIR_842nm = Band 8
  Red = Band 4

  return NDVI as numpy array
  """
  nir = data[:,7]
  red = data[:,3]
  ndvi = (nir - red) / (nir + red)
  ndvi[np.isnan(ndvi)] = -1
  return ndvi

def lswi_sentinel(data):
  """ 
  create LSWI from sentinel-2 image

  LSWI = NIR - SWIR / NIR + SWIR
  SWIR_1.6um = Band 11
  NIR = Band 9

  return NDVI as numpy array
  """
  nir = data[:,8]
  swir = data[:,9]
  lswi = (nir - swir) / (nir + swir)
  lswi[np.isnan(lswi)] = -1
  return lswi

def combine_images(src_data, ext_data):
  """ add externel data to the source data
  Data shape is [N,C,H,W] 
  N - number of images, C - channels, 
  H - height, W - width 
  ext_data can be [N,C,H,W] or [N,H,W]
  combination is along C colomn
  """
  src_shape = src_data.shape
  ext_shape = ext_data.shape
  # check if the shape is match
  if (src_shape[0] != ext_shape[0] 
      or src_shape[-1] != ext_shape[-1] 
      or src_shape[-2] != ext_shape[-2]):
    print("data size is not match")
  else:
    ext_data = ext_data.reshape(src_shape[0], -1,src_shape[-2], src_shape[-1])
    src_data = np.append(src_data,ext_data, 1)
  return src_data

def concat_vi(data,add_ndvi,add_lswi):
  """
  if add_ndvi is true
  """
  if add_ndvi:
    ndvi = ndvi_sentinel(data)
    ndvi2 = ndvi2_sentinel(data)
    data = combine_images(data,ndvi)
    data = combine_images(data,ndvi2)
  if add_lswi:
    lswi = lswi_sentinel(data)
    data = combine_images(data,lswi)
  return data

def get_h5_images(filename, keys, data_type, cat_vi, cat_cloud, cat_coord, cat_scl):
  """ get senntinel image from .h5 file
  return biomasses and images respectively"""
  dataset = h5py.File(filename, "r")
  for i, key in enumerate(keys):
    if key == 'agbd':
      biomasses = np.array(dataset[key],dtype= data_type )
    elif key == 'images':
      images = np.array(dataset[key],dtype= data_type )
      images = images.transpose(0,3,1,2)
      images = np.minimum(images / 10000, 1)

  if cat_vi:
    images = concat_vi(images,True,True)

  if cat_cloud:
    cloud = np.array(dataset['cloud'],dtype= data_type)
    cloud = cloud.transpose(0,3,1,2)
    images = np.append(images, cloud, 1)

  if cat_coord:
    lat = np.array(dataset['lat'],dtype= data_type)
    lat = lat.transpose(0,3,1,2)
    images = np.append(images, lat, 1)
    lon = np.array(dataset['lon'],dtype= data_type)
    lon = lon.transpose(0,3,1,2)
    images = np.append(images, lon, 1)
    
  if cat_scl:
    scl = np.array(dataset['scl'],dtype= data_type)
    scl = scl.transpose(0,3,1,2)
    images = np.append(images, scl, 1)
  return biomasses, images

import torch
class ABCDataset(torch.utils.data.Dataset):
    def __init__(self, images, labels, mean, std,  transform=None, target_transform=None):
        self.img_labels = labels
        self.img = images
        self.mean = mean
        self.std = std
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        # img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        
        image = self.img[idx]
        # image = np.minimum(image/10000,1)
        #image = (image-self.mean[:,None,None])/self.std[:,None,None] 
        # image = cv2.resize(image.transpose(1,2,0),(224,224))
        # image = image.transpose(2,0,1)
        

        # label = self.img_labels.iloc[idx, 1]
        label = self.img_labels[idx]

        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
            
        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.float)
		
		

import subprocess
if __name__ == 'main':

  train_url = 'https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_train.h5'
  val_url = 'https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_val.h5'
  test_url = 'https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_test.h5'
  # output_dir = '/path/to/output/dir'
  # subprocess.run(['wget', '-P', output_dir, url])

  train_file = "09072022_1154_train.h5"
  val_file = "09072022_1154_val.h5"
  test_file = "09072022_1154_test.h5"

  subprocess.run(['wget', '-O', train_file, url])
  subprocess.run(['wget', '-O', val_file, url])
  subprocess.run(['wget', '-O', train_file, url])

  """ we  're downloading a file from the URL 
  and saving it as train_file. 
  The -O option specifies the output file name for the downloaded content.
  """

  # <KeysViewHDF5 ['agbd', 'cloud', 'images', 'lat', 'lon', 'scl']>
  keys = ['agbd', 'images', 'cloud', 'lat', 'lon', 'scl']
  data_type = np.float64
  cat_vi = True
  cat_cloud = True
  cat_coord = True
  cat_scl = True

  train_biomasses, train_images = get_h5_images(train_file, keys, data_type, cat_vi, cat_cloud, cat_coord, cat_scl)
  validate_biomasses,validate_images = get_h5_images(val_file, keys, data_type, cat_vi, cat_cloud, cat_coord, cat_scl)
  test_biomasses,test_images = get_h5_images(test_file, keys, data_type, cat_vi, cat_cloud, cat_coord, cat_scl)